Custom LORA:

{'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight': tensor([[ 0.0188,  0.0170, -0.0252,  ...,  0.0311, -0.0171,  0.0113],
        [ 0.0195, -0.0047,  0.0063,  ...,  0.0376,  0.0090,  0.0236],
        [-0.0339, -0.0004,  0.0302,  ..., -0.0143, -0.0041,  0.0287],
        ...,
        [-0.0022, -0.0212, -0.0005,  ...,  0.0384,  0.0319,  0.0260],
        [ 0.0287, -0.0135, -0.0024,  ..., -0.0297,  0.0289, -0.0350],
        [-0.0016,  0.0302, -0.0193,  ...,  0.0066, -0.0319,  0.0327]],
       dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight': tensor([[ 3.6240e-03, -1.3123e-03,  2.2869e-03,  ...,  1.4391e-03,
         -7.1621e-04,  4.1504e-03],
        [ 5.3520e-03, -4.4823e-03, -3.9406e-03,  ..., -2.3670e-03,
          1.7586e-03, -1.1902e-03],
        [ 1.0090e-03, -6.2704e-04, -4.5433e-03,  ...,  2.6207e-03,
         -3.0518e-03, -9.2506e-04],
        ...,
        [ 6.4125e-03,  2.6760e-03,  1.3962e-03,  ...,  1.6413e-03,
          8.9407e-05, -1.4744e-03],
        [-3.9029e-04,  2.4586e-03, -1.5326e-03,  ..., -3.7384e-03,
         -3.0766e-03, -1.7614e-03],
        [-1.8239e-04, -1.3256e-03, -1.5516e-03,  ...,  1.5507e-03,
         -2.4776e-03, -2.0561e-03]], dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_mlp_fc2.lora_down.weight': tensor([[ 0.0081,  0.0022, -0.0058,  ..., -0.0018, -0.0068,  0.0085],
        [-0.0062,  0.0088, -0.0166,  ...,  0.0128, -0.0139, -0.0165],
        [ 0.0088,  0.0062,  0.0039,  ..., -0.0127, -0.0006,  0.0159],
        ...,
        [ 0.0077, -0.0143,  0.0149,  ..., -0.0036, -0.0107,  0.0163],
        [-0.0045, -0.0054, -0.0021,  ...,  0.0157, -0.0134,  0.0060],
        [-0.0175,  0.0018, -0.0083,  ..., -0.0176,  0.0011, -0.0189]],
       dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight': tensor([[ 1.1158e-04, -8.9788e-04, -3.0632e-03,  ...,  2.8038e-03,
         -1.2693e-03,  3.5119e-04],
        [ 8.0156e-04,  7.3481e-04,  5.1260e-04,  ..., -2.6417e-03,
          2.0084e-03, -4.3464e-04],
        [ 1.6842e-03,  2.4433e-03,  1.0628e-04,  ..., -2.3289e-03,
         -5.5361e-04,  8.3971e-04],
        ...,
        [ 7.1001e-04, -2.3479e-03, -1.3933e-03,  ..., -1.6489e-03,
          1.1978e-03, -1.3647e-03],
        [-1.5659e-03, -5.9652e-04, -3.4294e-03,  ..., -1.9207e-03,
          3.5133e-03, -3.7136e-03],
        [-6.8545e-05,  3.0327e-03, -5.3024e-04,  ..., -5.1804e-03,
          2.5997e-03, -7.1859e-04]], dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight': tensor([[-0.0270, -0.0316,  0.0274,  ...,  0.0189, -0.0361, -0.0084],
        [ 0.0204,  0.0162,  0.0214,  ...,  0.0154, -0.0358,  0.0129],
        [-0.0232, -0.0083, -0.0151,  ..., -0.0252, -0.0056,  0.0276],
        ...,
        [-0.0054,  0.0012,  0.0253,  ..., -0.0203,  0.0094,  0.0210],
        [-0.0175, -0.0235,  0.0028,  ...,  0.0379,  0.0022,  0.0270],
        [ 0.0294,  0.0179,  0.0291,  ...,  0.0035,  0.0109, -0.0084]],
       dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight': tensor([[ 2.2852e-04, -6.7234e-04, -1.9670e-05,  ...,  1.5688e-03,
         -1.0748e-03,  7.6675e-04],
        [ 4.7588e-04,  2.1439e-03,  2.6340e-03,  ...,  1.3704e-03,
          2.9087e-03,  9.9373e-04],
        [ 2.4624e-03,  1.4801e-03,  1.4124e-03,  ...,  2.0428e-03,
          2.5139e-03,  4.9543e-04],
        ...,
        [-5.5504e-03,  2.9011e-03, -1.3132e-03,  ...,  4.3449e-03,
          8.6546e-04, -8.3389e-03],
        [ 2.9373e-03,  2.2259e-03,  6.1378e-03,  ...,  8.3590e-04,
         -3.2597e-03, -7.4959e-03],
        [ 2.9106e-03,  2.3460e-03, -1.2932e-03,  ...,  1.0233e-03,
         -2.0301e-04, -5.9052e-03]], dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_down.weight': tensor([[ 0.0262,  0.0173, -0.0167,  ..., -0.0004,  0.0295, -0.0100],
        [-0.0126,  0.0150, -0.0192,  ..., -0.0215,  0.0246, -0.0242],
        [ 0.0213, -0.0266, -0.0120,  ...,  0.0231, -0.0310, -0.0203],
        ...,
        [ 0.0240, -0.0376,  0.0369,  ..., -0.0027, -0.0146,  0.0059],
        [ 0.0132,  0.0231, -0.0357,  ...,  0.0083, -0.0191,  0.0096],
        [-0.0377,  0.0339,  0.0338,  ...,  0.0180,  0.0028, -0.0267]],
       dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight': tensor([[ 3.0174e-03, -3.7308e-03, -4.8661e-04,  ...,  4.7188e-03,
          3.0231e-03,  1.9798e-03],
        [ 3.9649e-04, -3.4943e-03, -1.0214e-03,  ..., -1.8539e-03,
         -3.0270e-03, -3.0327e-03],
        [ 5.4646e-04,  3.2234e-04, -4.3535e-04,  ..., -1.9197e-03,
          3.6645e-04, -2.6417e-03],
        ...,
        [ 6.0081e-05, -8.6427e-06,  5.6744e-04,  ...,  1.4143e-03,
          3.5501e-04,  2.9526e-03],
        [-2.4033e-03,  8.8930e-04,  2.2717e-03,  ..., -6.6900e-04,
         -2.7885e-03, -4.1914e-04],
        [ 5.0087e-03, -2.0771e-03, -2.1305e-03,  ...,  3.5095e-03,
         -2.7542e-03,  1.5993e-03]], dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_down.weight': tensor([[ 0.0070,  0.0262, -0.0070,  ...,  0.0226,  0.0145, -0.0223],
        [ 0.0252,  0.0078,  0.0188,  ...,  0.0124, -0.0028, -0.0294],
        [ 0.0227, -0.0226,  0.0242,  ...,  0.0213,  0.0081, -0.0031],
        ...,
        [-0.0002, -0.0182,  0.0271,  ...,  0.0017, -0.0213, -0.0089],
        [-0.0105, -0.0069, -0.0066,  ...,  0.0004, -0.0238,  0.0032],
        [-0.0306,  0.0059, -0.0289,  ..., -0.0125,  0.0129, -0.0234]],
       dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_up.weight': tensor([[-1.3714e-03,  1.4248e-03,  1.5392e-03,  ...,  2.5415e-04,
          8.4639e-06, -2.0444e-05],
        [ 2.2316e-03, -4.3488e-03,  3.2291e-03,  ...,  8.7595e-04,
         -1.1551e-04, -1.9348e-04],
        [ 8.2779e-04,  7.6628e-04,  4.5853e-03,  ..., -1.1005e-03,
         -8.1348e-04, -5.6171e-04],
        ...,
        [ 2.3823e-03, -4.2191e-03,  2.3193e-03,  ...,  4.6425e-03,
          2.4307e-04,  4.8332e-03],
        [ 4.4518e-03, -8.8263e-04,  2.7227e-04,  ..., -2.1877e-03,
         -9.9301e-05,  2.1114e-03],
        [-9.6703e-04, -6.3658e-04, -1.2565e-04,  ..., -2.1210e-03,
          3.0041e-03,  3.2463e-03]], dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_down.weight': tensor([[-0.0188,  0.0098,  0.0286,  ..., -0.0071, -0.0368, -0.0165],
        [ 0.0083, -0.0264, -0.0120,  ..., -0.0096, -0.0312, -0.0018],
        [-0.0331,  0.0274,  0.0352,  ..., -0.0077, -0.0136, -0.0168],
        ...,
        [-0.0187,  0.0239,  0.0282,  ..., -0.0061, -0.0080,  0.0331],
        [ 0.0281,  0.0174,  0.0266,  ...,  0.0199,  0.0196,  0.0249],
        [ 0.0088,  0.0193, -0.0195,  ...,  0.0180,  0.0137,  0.0207]],
       dtype=torch.float16), 'lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_up.weight': tensor([[ 3.2635e-03,  2.4471e-03, -5.0020e-04,  ...,  4.5943e-04,
          1.7071e-03, -1.6088e-03],
        [ 5.3704e-05, -3.1719e-03,  2.2526e-03,  ..., -3.5524e-04,
         -1.0586e-03,  1.5192e-03],
        [ 1.7900e-03, -1.7099e-03, -1.4057e-03,  ..., -1.3666e-03,
          1.8129e-03,  3.6964e-03],
        ...,
        [ 1.1873e-03,  3.9902e-03,  4.0588e-03,  ..., -7.5531e-04,
          4.9591e-03,  2.6684e-03],
        [-4.0550e-03, -7.6294e-04, -2.5196e-03,  ..., -3.5801e-03,
         -3.4065e-03,  1.3113e-03],
        [ 2.3537e-03,  2.6741e-03,  2.0599e-03,  ...,  3.1834e-03,
         -6.3944e-04, -2.9755e-03]], dtype=torch.float16), 'lora_te_text_model_encoder_layers_10_mlp_fc1.lora_down.weight': tensor([[-0.0247, -0.0303, -0.0264,  ..., -0.0105,  0.0336,  0.0165],
        [-0.0071,  0.0168, -0.0303,  ...,  0.0137,  0.0023, -0.0163],
        [ 0.0077,  0.0365,  0.0362,  ..., -0.0173,  0.0058,  0.0364],
        ...,
        [ 0.0142,  0.0259, -0.0343,  ...,  0.0074,  0.0099, -0.0145],
        [ 0.0146, -0.0199,  0.0286,  ...,  0.0187, -0.0008, -0.0061],
        [ 0.0296,  0.0260,  0.0021,  ...,  0.0124,  0.0164, -0.0260]],
       dtype=torch.float16), 'lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up.weight': tensor([[-0.0059, -0.0046, -0.0010,  ...,  0.0073, -0.0013,  0.0016],
        [-0.0026,  0.0017,  0.0032,  ...,  0.0032, -0.0003,  0.0015],
        [ 0.0017, -0.0030, -0.0022,  ..., -0.0036, -0.0013,  0.0078],
        ...,
        [ 0.0003, -0.0013,  0.0030,  ...,  0.0025, -0.0006, -0.0055],
        [ 0.0020, -0.0027,  0.0016,  ...,  0.0011,  0.0031,  0.0022],
        [ 0.0023,  0.0005,  0.0009,  ...,  0.0077,  0.0043, -0.0004]],
       dtype=torch.float16), ...}


       
{'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight': tensor([[-0.0521, -0.3070, -0.3360,  ...,  0.1008,  0.1709,  0.0747],
        [-0.0733, -0.2325, -0.2173,  ..., -0.0447, -0.1712,  0.4272],
        [ 0.0019,  0.0486, -0.3028,  ...,  0.0657,  0.3815, -0.1191],
        [ 0.2683,  0.2717, -0.0166,  ..., -0.0191,  0.3422,  0.3405]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight': tensor([[ 0.0202, -0.0042,  0.0144, -0.0234],
        [ 0.0280, -0.0210, -0.0348, -0.0459],
        [-0.0260,  0.0213, -0.0212, -0.0198],
        ...,
        [-0.0203, -0.0271,  0.0578,  0.0152],
        [ 0.0197, -0.0155, -0.0089,  0.0125],
        [-0.0582, -0.0189,  0.0392,  0.0475]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.down.weight': tensor([[-0.0531, -0.1960, -0.3142,  ..., -0.1222,  0.1480, -0.4292],
        [-0.0049,  0.1779, -0.4511,  ...,  0.3213, -0.1077,  0.1550],
        [-0.2735,  0.1616, -0.2714,  ..., -0.1466,  0.3357, -0.0089],
        [-0.1511, -0.3442, -0.1907,  ..., -0.1579, -0.2617,  0.0663]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.up.weight': tensor([[-0.0028, -0.0283,  0.0348,  0.0120],
        [-0.0242, -0.0232, -0.0297, -0.0211],
        [ 0.0191, -0.0156, -0.0510,  0.0159],
        ...,
        [-0.0325,  0.0617,  0.0078,  0.0309],
        [ 0.0146, -0.0075,  0.0069, -0.0211],
        [-0.0627, -0.0679,  0.0144, -0.0008]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.down.weight': tensor([[-0.0813, -0.0823, -0.0006,  ..., -0.1714,  0.1837, -0.1382],
        [-0.1709,  0.3569, -0.1807,  ...,  0.2694, -0.0693, -0.4702],
        [-0.3379,  0.0151,  0.4268,  ...,  0.3780, -0.1871,  0.0484],
        [ 0.0804,  0.0006, -0.1082,  ..., -0.2927,  0.0142,  0.2253]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.up.weight': tensor([[-0.0178,  0.0480, -0.0404, -0.0313],
        [-0.0222, -0.0049,  0.0099,  0.0076],
        [ 0.0180,  0.0358,  0.0491,  0.0052],
        ...,
        [ 0.0244, -0.0022,  0.0520, -0.0053],
        [ 0.0131,  0.0327, -0.0125, -0.0246],
        [ 0.0014, -0.0190, -0.0327,  0.0110]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.down.weight': tensor([[ 0.1929, -0.2001, -0.0036,  ..., -0.1516,  0.1162, -0.1857],
        [ 0.1169, -0.5267, -0.1017,  ...,  0.4936, -0.2990,  0.1584],
        [-0.3750,  0.4035, -0.0066,  ..., -0.3858, -0.1949, -0.0612],
        [-0.3562, -0.0906, -0.2555,  ...,  0.1952,  0.0033,  0.1460]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.up.weight': tensor([[-0.0012,  0.0163,  0.0019,  0.0041],
        [ 0.0153,  0.0045, -0.0168,  0.0338],
        [ 0.0046,  0.0042, -0.0039, -0.0035],
        ...,
        [ 0.0032, -0.0100, -0.0064, -0.0021],
        [ 0.0212,  0.0038, -0.0352, -0.0057],
        [-0.0124, -0.0090,  0.0223, -0.0219]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.down.weight': tensor([[-0.4816, -0.3216, -0.2915,  ..., -0.1441, -0.1949,  0.3543],
        [-0.3741, -0.1821,  0.3673,  ..., -0.0556, -0.1416, -0.3204],
        [-0.0427, -0.1773, -0.2513,  ...,  0.0473, -0.1247,  0.1769],
        [ 0.0460, -0.0557,  0.0903,  ...,  0.2234,  0.0776, -0.0716]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.up.weight': tensor([[-0.0373,  0.0363, -0.0048, -0.0184],
        [-0.0110, -0.0073,  0.0301, -0.0238],
        [ 0.0189, -0.0151, -0.0006,  0.0121],
        ...,
        [ 0.0192,  0.0175, -0.0022, -0.0201],
        [ 0.0081, -0.0162,  0.0115,  0.0069],
        [ 0.0018,  0.0032,  0.0131,  0.0143]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.down.weight': tensor([[-0.0700,  0.0786,  0.3132,  ...,  0.2368,  0.0532, -0.1247],
        [ 0.0368, -0.0330,  0.2201,  ..., -0.0857, -0.1781,  0.1958],
        [ 0.1673, -0.0426, -0.1483,  ...,  0.1349,  0.1455,  0.2115],
        [-0.4073,  0.1931, -0.3989,  ..., -0.2339,  0.2825, -0.1852]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.up.weight': tensor([[-0.0059, -0.0380, -0.0207,  0.0134],
        [-0.0117, -0.0097, -0.0208,  0.0193],
        [ 0.0099,  0.0145,  0.0017, -0.0043],
        ...,
        [-0.0242, -0.0058, -0.0220,  0.0245],
        [-0.0184,  0.0084, -0.0162, -0.0007],
        [-0.0054, -0.0238, -0.0022, -0.0016]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.down.weight': tensor([[-0.0480,  0.1488, -0.0247,  ..., -0.7874, -0.0029, -0.3518],
        [ 0.1160,  0.0473,  0.1407,  ...,  0.0027,  0.0193,  0.2984],
        [ 0.1911,  0.3059,  0.3656,  ..., -0.3276,  0.0301, -0.2225],
        [-0.0594,  0.1144,  0.1781,  ...,  0.2373,  0.2112,  0.1135]]), 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.up.weight': tensor([[ 0.0305,  0.0334, -0.0008,  0.0280],
        [ 0.0211, -0.0132, -0.0272,  0.0306],
        [ 0.0150, -0.0081,  0.0065,  0.0146],
        ...,
        [-0.0457, -0.0297,  0.0312,  0.0165],
        [-0.0014, -0.0051,  0.0183,  0.0154],
        [ 0.0149,  0.0069, -0.0085,  0.0173]]), ...}